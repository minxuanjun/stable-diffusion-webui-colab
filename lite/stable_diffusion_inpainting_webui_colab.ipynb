{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minxuanjun/stable-diffusion-webui-colab/blob/main/lite/stable_diffusion_inpainting_webui_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaAJk33ppFw1"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "\n",
        "%env TF_CPP_MIN_LOG_LEVEL=1\n",
        "\n",
        "!apt -y update -qq\n",
        "!wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
        "%env LD_PRELOAD=/content/libtcmalloc_minimal.so.4\n",
        "\n",
        "!apt -y install -qq aria2 libcairo2-dev pkg-config python3-dev\n",
        "!pip install -q torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 torchtext==0.15.2 torchdata==0.6.1 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n",
        "!pip install -q xformers==0.0.20 triton==2.0.0 gradio_client==0.2.7 -U\n",
        "\n",
        "!git clone -b v2.4 https://github.com/camenduru/stable-diffusion-webui\n",
        "!git clone https://huggingface.co/embed/negative /content/stable-diffusion-webui/embeddings/negative\n",
        "!git clone https://huggingface.co/embed/lora /content/stable-diffusion-webui/models/Lora/positive\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/embed/upscale/resolve/main/4x-UltraSharp.pth -d /content/stable-diffusion-webui/models/ESRGAN -o 4x-UltraSharp.pth\n",
        "!wget https://raw.githubusercontent.com/camenduru/stable-diffusion-webui-scripts/main/run_n_times.py -O /content/stable-diffusion-webui/scripts/run_n_times.py\n",
        "!git clone -b v2.4 https://github.com/camenduru/deforum-for-automatic1111-webui /content/stable-diffusion-webui/extensions/deforum-for-automatic1111-webui\n",
        "!git clone -b v2.4 https://github.com/camenduru/stable-diffusion-webui-images-browser /content/stable-diffusion-webui/extensions/stable-diffusion-webui-images-browser\n",
        "!git clone -b v2.4 https://github.com/camenduru/stable-diffusion-webui-huggingface /content/stable-diffusion-webui/extensions/stable-diffusion-webui-huggingface\n",
        "!git clone -b v2.4 https://github.com/camenduru/sd-civitai-browser /content/stable-diffusion-webui/extensions/sd-civitai-browser\n",
        "!git clone -b v2.4 https://github.com/camenduru/sd-webui-additional-networks /content/stable-diffusion-webui/extensions/sd-webui-additional-networks\n",
        "!git clone -b v2.4 https://github.com/camenduru/sd-webui-tunnels /content/stable-diffusion-webui/extensions/sd-webui-tunnels\n",
        "!git clone -b v2.4 https://github.com/camenduru/batchlinks-webui /content/stable-diffusion-webui/extensions/batchlinks-webui\n",
        "!git clone -b v2.4 https://github.com/camenduru/stable-diffusion-webui-catppuccin /content/stable-diffusion-webui/extensions/stable-diffusion-webui-catppuccin\n",
        "!git clone -b v2.4 https://github.com/camenduru/stable-diffusion-webui-rembg /content/stable-diffusion-webui/extensions/stable-diffusion-webui-rembg\n",
        "!git clone -b v2.4 https://github.com/camenduru/stable-diffusion-webui-two-shot /content/stable-diffusion-webui/extensions/stable-diffusion-webui-two-shot\n",
        "!git clone -b v2.4 https://github.com/camenduru/sd-webui-aspect-ratio-helper /content/stable-diffusion-webui/extensions/sd-webui-aspect-ratio-helper\n",
        "!git clone -b v2.4 https://github.com/camenduru/asymmetric-tiling-sd-webui /content/stable-diffusion-webui/extensions/asymmetric-tiling-sd-webui\n",
        "%cd /content/stable-diffusion-webui\n",
        "!git reset --hard\n",
        "!git -C /content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai reset --hard\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/i15/resolve/main/sd-v1-5-inpainting.ckpt -d /content/stable-diffusion-webui/models/Stable-diffusion -o sd-v1-5-inpainting.ckpt\n",
        "\n",
        "!sed -i -e '''/from modules import launch_utils/a\\import os''' /content/stable-diffusion-webui/launch.py\n",
        "!sed -i -e '''/        prepare_environment()/a\\        os.system\\(f\\\"\"\"sed -i -e ''\\\"s/dict()))/dict())).cuda()/g\\\"'' /content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\"\"\")''' /content/stable-diffusion-webui/launch.py\n",
        "!sed -i -e 's/\\[\"sd_model_checkpoint\"\\]/\\[\"sd_model_checkpoint\",\"sd_vae\",\"CLIP_stop_at_last_layers\"\\]/g' /content/stable-diffusion-webui/modules/shared.py\n",
        "\n",
        "!python launch.py --listen --xformers --enable-insecure-extension-access --theme dark --gradio-queue --multiple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import diffusers\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "base_model = \"runwayml/stable-diffusion-v1-5\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(base_model, torch_dtype=torch.float16)"
      ],
      "metadata": {
        "id": "WkkX59aAc9s-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipe.components)\n",
        "print(type(pipe.components))\n"
      ],
      "metadata": {
        "id": "J6NBKPeIecoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "PnKGVALrsidc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLip tokenizer [Text Encoder tutorail](https://zhuanlan.zhihu.com/p/680103276)\n",
        "\n",
        "CLIPTokenizer 会将文本拆分成各个单词，然后使用查表法将每个子单词转换为数字。\n",
        "其中每个prompt 编码的最大长度是77。每个编码出的序列都有一些固定的token. *start_token*, *end_token*.\n",
        "```python\n",
        "'tokenizer': CLIPTokenizer(name_or_path='/root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/f03de327dd89b501a01da37fc5240cf4fdba85a1/tokenizer', vocab_size=49408, model_max_length=77, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|startoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'\n",
        "    }, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
        "        49406: AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
        "        49407: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
        "    }\n",
        "```"
      ],
      "metadata": {
        "id": "b1De2Qjwogg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = pipe.components[\"tokenizer\"]\n",
        "print(type(tokenizer))\n",
        "prompt = [\"a dog wearning hat\"]\n",
        "prompt = ['tokenizer = pipe.components[\"tokenizer\"]']\n",
        "text_token = tokenizer(prompt, padding=\"max_length\", max_length = tokenizer.model_max_length, truncation=True, return_tensors = \"pt\")\n",
        "text_token = text_token.to(\"cpu\")\n",
        "print(text_token.input_ids.shape)\n",
        "print(text_token)\n",
        "\n",
        "for token in list(text_token.input_ids[0,:7]):\n",
        "  print(f\"{token}:{tokenizer.convert_ids_to_tokens(int(token.item()))}\")"
      ],
      "metadata": {
        "id": "o5J1GLgCr3Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Encoder\n",
        "Text Encoder 就是将将tokenizer 生成的input_ids 转化为一个文本嵌入的特征，文本嵌入的特征维度是768。Text Encoder 就是， 输出特征维度是[77,768]\n",
        "\n",
        "```python\n",
        "'text_encoder': CLIPTextModel(\n",
        "  (text_model): CLIPTextTransformer(\n",
        "    (embeddings): CLIPTextEmbeddings(\n",
        "      (token_embedding): Embedding(49408,\n",
        "    768)\n",
        "      (position_embedding): Embedding(77,\n",
        "    768)\n",
        "    )\n",
        "    (encoder): CLIPEncoder(\n",
        "      (layers): ModuleList(\n",
        "        (0-11): 12 x CLIPEncoderLayer(\n",
        "          (self_attn): CLIPAttention(\n",
        "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
        "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
        "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
        "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
        "          )\n",
        "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
        "          (mlp): CLIPMLP(\n",
        "            (activation_fn): QuickGELUActivation()\n",
        "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
        "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
        "          )\n",
        "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
        "        )\n",
        "      )\n",
        "    )\n",
        "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
        "  )\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "NSUdLBsWv1-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_encoder = pipe.components[\"text_encoder\"]\n",
        "# get model structure\n",
        "print(text_encoder)\n",
        "\n",
        "with torch.no_grad():\n",
        "  text_embed = text_encoder(text_token.input_ids.to(\"cuda\"))\n",
        "# print(text_embed)\n",
        "print(f\"hidden {text_embed.last_hidden_state.shape}  {text_embed.pooler_output.shape}\")\n"
      ],
      "metadata": {
        "id": "DUIwQcdd6SdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们可以通过控制  `num_inference_steps` 来控制去噪次数，去噪次数越多，结果越好。 默认值是50."
      ],
      "metadata": {
        "id": "xP15566OAkWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a photograph of an astronaut riding a horse\"\n",
        "%debug image = pipe(prompt, num_inference_steps=15).images[0]  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
        "\n",
        "# Now to display an image you can either save it such as:\n",
        "image.save(f\"astronaut_rides_horse.png\")\n",
        "\n",
        "# or if you're in a google colab you can directly display it with\n",
        "image"
      ],
      "metadata": {
        "id": "_Ij_aqPp_VzC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}